<!DOCTYPE html>
<html lang="en">

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    
    <meta name="description" content="strconv - 我是一个Golang模块">
    <meta name="keywords" content="golang,go">

    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="用Golang写爬虫(一)"/>
<meta name="twitter:description" content="之前一直都是再用Python写爬虫，最近想体验下Golang写爬虫的感觉，所以就有了这个系列。我想要抓取的页面是豆瓣Top250页面，选择它的理由有3个:
 豆瓣页面代码相对规范 豆瓣对爬虫爱好者相对更宽容 Top250页面简洁，很适合拿来练手  我们先看第一版的代码。
按逻辑我把抓取代码分成2个部分：
 HTTP请求 解析页面中的内容  我们先看HTTP请求，Golang语言的HTTP请求库不需要使用第三方的库，标准库就内置了足够好的支持：
import ( &#34;fmt&#34; &#34;net/http&#34; &#34;io/ioutil&#34; ) func fetch (url string) string { fmt.Println(&#34;Fetch Url&#34;, url) client := &amp;http.Client{} req, _ := http.NewRequest(&#34;GET&#34;, url, nil) req.Header.Set(&#34;User-Agent&#34;, &#34;Mozilla/5.0 (compatible; Googlebot/2.1; &#43;http://www.google.com/bot.html)&#34;) resp, err := client.Do(req) if err != nil { fmt.Println(&#34;Http get err:&#34;, err) return &#34;&#34; } if resp.StatusCode != 200 { fmt.Println(&#34;Http status code:&#34;, resp.StatusCode) return &#34;&#34; } defer resp."/>

    <meta property="og:title" content="用Golang写爬虫(一)" />
<meta property="og:description" content="之前一直都是再用Python写爬虫，最近想体验下Golang写爬虫的感觉，所以就有了这个系列。我想要抓取的页面是豆瓣Top250页面，选择它的理由有3个:
 豆瓣页面代码相对规范 豆瓣对爬虫爱好者相对更宽容 Top250页面简洁，很适合拿来练手  我们先看第一版的代码。
按逻辑我把抓取代码分成2个部分：
 HTTP请求 解析页面中的内容  我们先看HTTP请求，Golang语言的HTTP请求库不需要使用第三方的库，标准库就内置了足够好的支持：
import ( &#34;fmt&#34; &#34;net/http&#34; &#34;io/ioutil&#34; ) func fetch (url string) string { fmt.Println(&#34;Fetch Url&#34;, url) client := &amp;http.Client{} req, _ := http.NewRequest(&#34;GET&#34;, url, nil) req.Header.Set(&#34;User-Agent&#34;, &#34;Mozilla/5.0 (compatible; Googlebot/2.1; &#43;http://www.google.com/bot.html)&#34;) resp, err := client.Do(req) if err != nil { fmt.Println(&#34;Http get err:&#34;, err) return &#34;&#34; } if resp.StatusCode != 200 { fmt.Println(&#34;Http status code:&#34;, resp.StatusCode) return &#34;&#34; } defer resp." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://strconv.com/posts/web-crawler-exercise-1/" />
<meta property="article:published_time" content="2019-07-04T00:00:00&#43;00:00"/>
<meta property="article:modified_time" content="2019-07-04T00:00:00&#43;00:00"/>


    
      <base href="https://strconv.com/posts/web-crawler-exercise-1/">
    
    <title>
  用Golang写爬虫(一) · strconv
</title>

    
      <link rel="canonical" href="https://strconv.com/posts/web-crawler-exercise-1/">
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous" />
    
    
    <link rel="stylesheet" href="https://strconv.com/css/normalize.css" integrity="" crossorigin="anonymous" media="screen" />
    
    
    <link rel="stylesheet" href="https://strconv.com/css/coder.css" media="screen">

    

    

    

    

    <link rel="icon" type="image/png" href="https://strconv.com/images/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://strconv.com/images/favicon-16x16.png" sizes="16x16">

    <meta name="generator" content="Hugo 0.55.6" />
  </head>

  <body class=" ">
    <main class="wrapper">
      <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="https://strconv.com">
      strconv
    </a>
    <input type="checkbox" id="menu-toggle" />
    <label class="menu-button float-right" for="menu-toggle"><i class="fas fa-bars"></i></label>
    <ul class="navigation-list">
      
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://strconv.com/">Home</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://strconv.com/tags/">Tags</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://strconv.com/categories/">Categories</a>
          </li>
        
          <li class="navigation-item">
            <a class="navigation-link" href="https://strconv.com/about/">About</a>
          </li>
        
      
      
    </ul>
  </section>
</nav>


      <div class="content">
        
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">用Golang写爬虫(一)</h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fas fa-calendar"></i>
              <time datetime='2019-07-04T00:00:00Z'>
                July 4, 2019
              </time>
            </span>
            <span class="reading-time">
              <i class="fas fa-clock"></i>
              One minute read
            </span>
          </div>
          <div class="categories">
  <i class="fas fa-folder"></i>
    <a href="https://strconv.com/categories/crawler/">crawler</a></div>

          <div class="tags">
  <i class="fas fa-tag"></i>
    <a href="https://strconv.com/tags/crawler/">crawler</a></div>

        </div>
      </header>

      <div>
        

<p>之前一直都是再用Python写爬虫，最近想体验下Golang写爬虫的感觉，所以就有了这个系列。我想要抓取的页面是<a href="https://movie.douban.com/top250">豆瓣Top250页面</a>，选择它的理由有3个:</p>

<ol>
<li>豆瓣页面代码相对规范</li>
<li>豆瓣对爬虫爱好者相对更宽容</li>
<li>Top250页面简洁，很适合拿来练手</li>
</ol>

<p>我们先看第一版的代码。</p>

<p>按逻辑我把抓取代码分成2个部分：</p>

<ol>
<li>HTTP请求</li>
<li>解析页面中的内容</li>
</ol>

<p>我们先看HTTP请求，Golang语言的HTTP请求库不需要使用第三方的库，标准库就内置了足够好的支持：</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#ff79c6">import</span> (
	<span style="color:#f1fa8c">&#34;fmt&#34;</span>
	<span style="color:#f1fa8c">&#34;net/http&#34;</span>
	<span style="color:#f1fa8c">&#34;io/ioutil&#34;</span>
)

<span style="color:#8be9fd;font-style:italic">func</span> <span style="color:#50fa7b">fetch</span> (url <span style="color:#8be9fd">string</span>) <span style="color:#8be9fd">string</span> {
	fmt.<span style="color:#50fa7b">Println</span>(<span style="color:#f1fa8c">&#34;Fetch Url&#34;</span>, url)
	client <span style="color:#ff79c6">:=</span> <span style="color:#ff79c6">&amp;</span>http.Client{}
	req, _ <span style="color:#ff79c6">:=</span> http.<span style="color:#50fa7b">NewRequest</span>(<span style="color:#f1fa8c">&#34;GET&#34;</span>, url, <span style="color:#ff79c6">nil</span>)
	req.Header.<span style="color:#50fa7b">Set</span>(<span style="color:#f1fa8c">&#34;User-Agent&#34;</span>, <span style="color:#f1fa8c">&#34;Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)&#34;</span>)
	resp, err <span style="color:#ff79c6">:=</span> client.<span style="color:#50fa7b">Do</span>(req)
	<span style="color:#ff79c6">if</span> err <span style="color:#ff79c6">!=</span> <span style="color:#ff79c6">nil</span> {
		fmt.<span style="color:#50fa7b">Println</span>(<span style="color:#f1fa8c">&#34;Http get err:&#34;</span>, err)
        <span style="color:#ff79c6">return</span> <span style="color:#f1fa8c">&#34;&#34;</span>
	}
	<span style="color:#ff79c6">if</span> resp.StatusCode <span style="color:#ff79c6">!=</span> <span style="color:#bd93f9">200</span> {
		fmt.<span style="color:#50fa7b">Println</span>(<span style="color:#f1fa8c">&#34;Http status code:&#34;</span>, resp.StatusCode)
		<span style="color:#ff79c6">return</span> <span style="color:#f1fa8c">&#34;&#34;</span>
	}
	<span style="color:#ff79c6">defer</span> resp.Body.<span style="color:#50fa7b">Close</span>()
	body, err <span style="color:#ff79c6">:=</span> ioutil.<span style="color:#50fa7b">ReadAll</span>(resp.Body)
	<span style="color:#ff79c6">if</span> err <span style="color:#ff79c6">!=</span> <span style="color:#ff79c6">nil</span> {
		fmt.<span style="color:#50fa7b">Println</span>(<span style="color:#f1fa8c">&#34;Read error&#34;</span>, err)
		<span style="color:#ff79c6">return</span> <span style="color:#f1fa8c">&#34;&#34;</span>
	}
	<span style="color:#ff79c6">return</span> <span style="color:#8be9fd;font-style:italic">string</span>(body)
}</code></pre></div>

<p>我把URL请求的逻辑都放在了fetch函数中，里面做了一些异常处理。值得说的有2点：</p>

<ol>
<li>在Header中设置了User-Agent，让访问看起来更像搜索引擎Bot。如果一个网站希望自己的内容被Google收录那么他就不会拒绝这样的UA的访问。</li>
<li>需要通过ioutil.ReadAll 读取resp的body内容，最后用string(body)把它转化成字符串</li>
</ol>

<p>接着就是解析页面的部分：</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#ff79c6">import</span> (
    <span style="color:#f1fa8c">&#34;regexp&#34;</span>
	<span style="color:#f1fa8c">&#34;strings&#34;</span>
)

<span style="color:#8be9fd;font-style:italic">func</span> <span style="color:#50fa7b">parseUrls</span>(url <span style="color:#8be9fd">string</span>) {
	body <span style="color:#ff79c6">:=</span> <span style="color:#50fa7b">fetch</span>(url)
	body = strings.<span style="color:#50fa7b">Replace</span>(body, <span style="color:#f1fa8c">&#34;\n&#34;</span>, <span style="color:#f1fa8c">&#34;&#34;</span>, <span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>)
	rp <span style="color:#ff79c6">:=</span> regexp.<span style="color:#50fa7b">MustCompile</span>(<span style="color:#f1fa8c">`&lt;div class=&#34;hd&#34;&gt;(.*?)&lt;/div&gt;`</span>)
	titleRe <span style="color:#ff79c6">:=</span> regexp.<span style="color:#50fa7b">MustCompile</span>(<span style="color:#f1fa8c">`&lt;span class=&#34;title&#34;&gt;(.*?)&lt;/span&gt;`</span>)
	idRe <span style="color:#ff79c6">:=</span> regexp.<span style="color:#50fa7b">MustCompile</span>(<span style="color:#f1fa8c">`&lt;a href=&#34;https://movie.douban.com/subject/(\d+)/&#34;`</span>)
	items <span style="color:#ff79c6">:=</span> rp.<span style="color:#50fa7b">FindAllStringSubmatch</span>(body, <span style="color:#ff79c6">-</span><span style="color:#bd93f9">1</span>)
	<span style="color:#ff79c6">for</span> _, item <span style="color:#ff79c6">:=</span> <span style="color:#ff79c6">range</span> items {
		fmt.<span style="color:#50fa7b">Println</span>(idRe.<span style="color:#50fa7b">FindStringSubmatch</span>(item[<span style="color:#bd93f9">1</span>])[<span style="color:#bd93f9">1</span>],
			titleRe.<span style="color:#50fa7b">FindStringSubmatch</span>(item[<span style="color:#bd93f9">1</span>])[<span style="color:#bd93f9">1</span>])
	}
}</code></pre></div>

<p>这篇文章我们主要体验用标准库完成页面的解析，也就是用正则表达式包regexp来完成。不过要注意需要用<code>strings.Replace(body, &quot;\n&quot;, &quot;&quot;, -1)</code>这步把body内容中的回车符去掉，要不然下面的正则表达式<code>.*</code>就不符合了。<code>FindAllStringSubmatch</code>方法会把符合正则表达式的结果都解析出来（一个列表），而<code>FindStringSubmatch</code>是找第一个符合的结果。</p>

<p>Top250页面是要翻页的，最后在main函数里面实现抓取全部Top250页面。另外为了和之后的改进做对比，我们加上代码运行耗时的逻辑：</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-go" data-lang="go"><span style="color:#ff79c6">import</span> (
       <span style="color:#f1fa8c">&#34;time&#34;</span>
       <span style="color:#f1fa8c">&#34;strconv&#34;</span>
)
<span style="color:#8be9fd;font-style:italic">func</span> <span style="color:#50fa7b">main</span>() {
        start <span style="color:#ff79c6">:=</span> time.<span style="color:#50fa7b">Now</span>()
        <span style="color:#ff79c6">for</span> i <span style="color:#ff79c6">:=</span> <span style="color:#bd93f9">0</span>; i &lt; <span style="color:#bd93f9">10</span>; i<span style="color:#ff79c6">++</span> {
                <span style="color:#50fa7b">parseUrls</span>(<span style="color:#f1fa8c">&#34;https://movie.douban.com/top250?start=&#34;</span> <span style="color:#ff79c6">+</span> strconv.<span style="color:#50fa7b">Itoa</span>(<span style="color:#bd93f9">25</span> <span style="color:#ff79c6">*</span> i))
        }
        elapsed <span style="color:#ff79c6">:=</span> time.<span style="color:#50fa7b">Since</span>(start)
        fmt.<span style="color:#50fa7b">Printf</span>(<span style="color:#f1fa8c">&#34;Took %s&#34;</span>, elapsed)
}</code></pre></div>

<p>在Golang中把数字转成字符串需要使用<code>strconv.Itoa</code>（嘿嘿，本博客域名就是这个模块），这样就可以根据start的参数的不通拼出正确的页面路径。用一个for循环完成翻页。</p>

<p>运行起来非常快：</p>

<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">❯ go run crawler/doubanCrawler1.go
... <span style="color:#6272a4"># 省略输出</span>
Took <span style="color:#bd93f9">1</span>.454627547s</code></pre></div>

<p>通过终端输出可以看到我们拿到了对应电影条目的ID和电影标题！</p>

<h3 id="代码地址">代码地址</h3>

<p>完整代码可以在<a href="https://github.com/golang-dev/strconv.code/blob/master/crawler/doubanCrawler1.go">这个地址</a>找到。</p>

      </div>

      <footer>
        


        
        <div id="commento"></div>
<script src="https://cdn.commento.io/js/commento.js"></script>
      </footer>
    </article>

    
  </section>

      </div>

      <footer class="footer">
  <section class="container">
    
      <p>我是一个Golang模块.</p>
    
     © 2020
    
       · 
      Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
    
  </section>
</footer>

    </main>

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-143191829-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


  </body>

</html>
